{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ST_CASE  DRUGRES\n",
      "0    10001        0\n",
      "1    10002        0\n",
      "2    10002        0\n",
      "3    10003        1\n",
      "4    10003        1\n"
     ]
    }
   ],
   "source": [
    "data_1 = pd.read_csv('data/Drugs_2018.csv')\n",
    "\n",
    "# extract the drug feature\n",
    "data_1 = data_1[['ST_CASE', 'DRUGRES']]\n",
    "#for the DRUGRES column, make 0 and 1 as 0, and others as 1\n",
    "data_1['DRUGRES'] = data_1['DRUGRES'].apply(lambda x: 0 if x in [0,1]  else 1)\n",
    "print(data_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/plt56vgx1nx_6xff98fhl2dc0000gn/T/ipykernel_10212/616569146.py:3: DtypeWarning: Columns (40,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(accident_file, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305137, 8)\n",
      "   ST_CASE        LGT_CONDNAME WEATHERNAME RUR_URBNAME  DRUNK_DR  DRUGRES  \\\n",
      "0    10001                Dawn       Clear       Rural         0        0   \n",
      "1    10002  Dark - Not Lighted        Rain       Urban         0        0   \n",
      "2    10002  Dark - Not Lighted        Rain       Urban         0        0   \n",
      "3    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "4    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "\n",
      "   PERSONS  FATALS  \n",
      "0        1       1  \n",
      "1        2       2  \n",
      "2        2       2  \n",
      "3        2       1  \n",
      "4        2       1  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(accident_file, drugs_file):\n",
    "\n",
    "    data = pd.read_csv(accident_file, encoding='latin1')\n",
    "    data = data[[ 'ST_CASE', 'LGT_CONDNAME', 'WEATHERNAME', 'RUR_URBNAME' ,'DRUNK_DR', 'PERSONS', 'FATALS']]\n",
    "    data_1 = pd.read_csv(drugs_file)\n",
    "    # extract the drug feature\n",
    "    data_1 = data_1[['ST_CASE', 'DRUGRES']]\n",
    "    data_1['DRUGRES'] = data_1['DRUGRES'].apply(lambda x: 0 if x in [0, 1] else 1)\n",
    "\n",
    "     # merge the two datasets\n",
    "    data = pd.merge(data, data_1, on='ST_CASE', how='left')\n",
    "    \n",
    "    columns = list(data.columns)\n",
    "    # get the new columns\n",
    "    new_columns = [col for col in data_1.columns if col not in data.columns[:-len(data_1.columns)]]\n",
    "    # move the new columns to the second last position\n",
    "    for col in new_columns:\n",
    "        columns.remove(col)\n",
    "        columns.insert(-2, col)\n",
    "    # re-order the columns\n",
    "    data = data[columns]\n",
    "    \n",
    "    return data\n",
    "\n",
    "data_2018 = preprocess_data('data/accident_2018.csv', 'data/Drugs_2018.csv')\n",
    "data_2019 = preprocess_data('data/accident_2019.csv', 'data/Drugs_2019.csv')\n",
    "data_2020 = preprocess_data('data/accident_2020.csv', 'data/Drugs_2020.csv')\n",
    "\n",
    "\n",
    "# merge all the data\n",
    "all_data = pd.concat([data_2018, data_2019, data_2020,], ignore_index=True)\n",
    "\n",
    "print(all_data.shape)\n",
    "print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282238, 7)\n",
      "   ST_CASE        LGT_CONDNAME WEATHERNAME RUR_URBNAME  DRUNK_DR  DRUGRES  \\\n",
      "0    10001                Dawn       Clear       Rural         0        0   \n",
      "1    10002  Dark - Not Lighted        Rain       Urban         0        0   \n",
      "2    10002  Dark - Not Lighted        Rain       Urban         0        0   \n",
      "3    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "4    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "5    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "6    10003  Dark - Not Lighted      Cloudy       Rural         0        1   \n",
      "7    10003  Dark - Not Lighted      Cloudy       Rural         0        0   \n",
      "8    10004            Daylight      Cloudy       Rural         0        0   \n",
      "9    10004            Daylight      Cloudy       Rural         0        0   \n",
      "\n",
      "   MortalRate  \n",
      "0         1.0  \n",
      "1         1.0  \n",
      "2         1.0  \n",
      "3         0.5  \n",
      "4         0.5  \n",
      "5         0.5  \n",
      "6         0.5  \n",
      "7         0.5  \n",
      "8         0.5  \n",
      "9         0.5  \n"
     ]
    }
   ],
   "source": [
    "# first, remove the person that is 0\n",
    "\n",
    "all_data = all_data[all_data['PERSONS'] > 0]\n",
    "\n",
    "all_data['MortalRate'] = (all_data['FATALS'] / all_data['PERSONS']).apply(lambda x: round(x, 2))\n",
    "all_data.drop(['FATALS', 'PERSONS'], axis=1, inplace=True)\n",
    "\n",
    "all_data = all_data.dropna()\n",
    "\n",
    "# filter the columns that is not useful for LGT and WEATHER\n",
    "values_to_remove = ['Not Reported', 'Other', 'Reported as Unknown', 'Trafficway Not in State Inventory', 'Unknown']\n",
    "all_data = all_data[\n",
    "    ~all_data['LGT_CONDNAME'].isin(values_to_remove) &\n",
    "    ~all_data['WEATHERNAME'].isin(values_to_remove) &\n",
    "    ~all_data['RUR_URBNAME'].isin(values_to_remove)\n",
    "]\n",
    "\n",
    "# becasue drunk feature have different values, make them to be 0 or 1(drunk)\n",
    "all_data['DRUNK_DR'] = all_data['DRUNK_DR'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# print how many data points are left\n",
    "print(all_data.shape)\n",
    "print(all_data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle the feature, make LGT to dark and light\n",
    "lgt_cond_mapping = {\n",
    "    'Daylight': 'light',\n",
    "    'Dawn': 'light',\n",
    "    'Dusk': 'light',\n",
    "    'Dark - Lighted': 'dark',\n",
    "    'Dark - Not Lighted': 'dark',\n",
    "    'Dark - Unknown Lighting': 'dark'\n",
    "}\n",
    "\n",
    "weather1_mapping = {\n",
    "    'Clear': 'Clear',\n",
    "    'Rain': 'Rain',\n",
    "    'Freezing Rain or Drizzle': 'Rain',\n",
    "    'Snow': 'Snow',\n",
    "    'Sleet or Hail': 'Snow',\n",
    "    'Blowing Snow': 'Snow',\n",
    "    'Severe Crosswinds': 'Windy',\n",
    "    'Blowing Sand, Soil, Dirt': 'Windy',\n",
    "    'Cloudy': 'Cloudy',\n",
    "    'Fog, Smog, Smoke': 'Cloudy'\n",
    "}\n",
    "\n",
    "all_data['LGT_CONDNAME'] = all_data['LGT_CONDNAME'].map(lgt_cond_mapping)\n",
    "all_data['WEATHERNAME'] = all_data['WEATHERNAME'].map(weather1_mapping)\n",
    "\n",
    "# fill the missing values\n",
    "all_data['LGT_CONDNAME'] = all_data['LGT_CONDNAME'].fillna('unknown')\n",
    "all_data['WEATHERNAME'] = all_data['WEATHERNAME'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGT_CONDNAME unique values: ['light' 'dark']\n",
      "WEATHERNAME unique values: ['Clear' 'Rain' 'Cloudy' 'Windy' 'Snow']\n",
      "RUR_URBNAME unique values: ['Rural' 'Urban']\n",
      "DRUNK_DR unique values: [0 1]\n",
      "DRUGRES unique values: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# print the different values of different features\n",
    "print(\"LGT_CONDNAME unique values:\", all_data['LGT_CONDNAME'].unique())\n",
    "print(\"WEATHERNAME unique values:\", all_data['WEATHERNAME'].unique())\n",
    "print(\"RUR_URBNAME unique values:\", all_data['RUR_URBNAME'].unique())\n",
    "print(\"DRUNK_DR unique values:\", all_data['DRUNK_DR'].unique())\n",
    "print(\"DRUGRES unique values:\", all_data['DRUGRES'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.096144568\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# select the features and target variable\n",
    "selected_features = ['LGT_CONDNAME', 'WEATHERNAME', 'RUR_URBNAME' ,'DRUNK_DR', 'DRUGRES']\n",
    "X = all_data[selected_features]\n",
    "y = all_data['MortalRate']  # targert variable is the MortalRate\n",
    "\n",
    "# make the features to be one-hot encoding\n",
    "categorical_features = ['LGT_CONDNAME', 'WEATHERNAME']\n",
    "numerical_features = ['DRUNK_DR', 'DRUGRES']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# create a pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(max_depth=5, random_state=20))\n",
    "])\n",
    "\n",
    "# dataset split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse:.9f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Predictions:\n",
      "  LGT_CONDNAME WEATHERNAME RUR_URBNAME  DRUNK_DR  DRUGRES  Prediction\n",
      "0        light       Clear       Rural         0        0    0.440774\n",
      "1        light       Clear       Rural         0        1    0.584585\n",
      "2        light       Clear       Rural         1        0    0.459711\n",
      "3        light       Clear       Rural         1        1    0.627521\n",
      "4        light       Clear       Urban         0        0    0.440774\n",
      "5        light       Clear       Urban         0        1    0.584585\n",
      "6        light       Clear       Urban         1        0    0.459711\n",
      "7        light       Clear       Urban         1        1    0.627521\n",
      "8        light        Rain       Rural         0        0    0.415281\n",
      "9         dark       Clear       Rural         0        0    0.559453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t9/plt56vgx1nx_6xff98fhl2dc0000gn/T/ipykernel_10212/1109627513.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  example_data = example_data.append({'LGT_CONDNAME': 'dark', 'WEATHERNAME': 'Clear', 'RUR_URBNAME': 'Rural', 'DRUNK_DR': 0, 'DRUGRES': 0}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# test, example data\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "lgt_cond_values = ['light', 'dark']\n",
    "weather_values = ['Clear', 'Rain']\n",
    "rur_urb_values = ['Rural', 'Urban']\n",
    "drunk_dr_values = [0, 1]\n",
    "drugres_values = [0, 1]\n",
    "\n",
    "# generate all possible combinations of the values\n",
    "combinations = list(itertools.product(lgt_cond_values, weather_values, rur_urb_values, drunk_dr_values, drugres_values))\n",
    "\n",
    "# create a DataFrame with the combinations\n",
    "example_data = pd.DataFrame(combinations[:9], columns=['LGT_CONDNAME', 'WEATHERNAME', 'RUR_URBNAME', 'DRUNK_DR', 'DRUGRES'])\n",
    "example_data = example_data.append({'LGT_CONDNAME': 'dark', 'WEATHERNAME': 'Clear', 'RUR_URBNAME': 'Rural', 'DRUNK_DR': 0, 'DRUGRES': 0}, ignore_index=True)\n",
    "\n",
    "example_data_encoded = preprocessor.transform(example_data)\n",
    "\n",
    "\n",
    "example_predictions = model.named_steps['regressor'].predict(example_data_encoded)\n",
    "\n",
    "example_data['Prediction'] = example_predictions\n",
    "print(\"Example Predictions:\")\n",
    "print(example_data[['LGT_CONDNAME', 'WEATHERNAME', 'RUR_URBNAME', 'DRUNK_DR', 'DRUGRES', 'Prediction']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
